# caffe 的 python 接口和用 c++ 调用 caffemodel

---

Creation Time: 2020/06/11

---

[TOC]

## 一、生成网络文件

1. 数据是 LMDB 的格式

    ```python
    from caffe import layers as L,params as P,to_proto

    path = '/home/xxx/data/'                    #  项目路径
    train_lmdb = path+'train_db'                # （读）训练数据LMDB文件的位置
    val_lmdb = path+'val_db'                    # （读）验证数据LMDB文件的位置
    mean_file = path+'mean.binaryproto'         # （读）均值文件的位置
    train_proto = path+'train.prototxt'         # （写）生成的训练配置文件保存的位置
    val_proto = path+'val.prototxt'             # （写）生成的验证配置文件保存的位置

    #编写一个函数，用于生成网络（注意这个网络配置需要根据实际需要编写）
    def create_net(lmdb,batch_size,include_acc=False):
        #创建第一层：数据层。向上传递两类数据：图片数据和对应的标签
        data, label = L.Data(source=lmdb, backend=P.Data.LMDB,  batch_size=batch_size, ntop=2,
            transform_param=dict(crop_size=40,mean_file=mean_file,  mirror=True))
        #创建第二屋：卷积层
        conv1=L.Convolution(data, kernel_size=5, stride=1,  num_output=16, pad=2,weight_filler=dict(type='xavier'))
        #创建激活函数层
        relu1=L.ReLU(conv1, in_place=True)
        #创建池化层
        pool1=L.Pooling(relu1, pool=P.Pooling.MAX, kernel_size=3,   stride=2)
        conv2=L.Convolution(pool1, kernel_size=3, stride=1, num_output=32, pad=1,weight_filler=dict(type='xavier'))
        relu2=L.ReLU(conv2, in_place=True)
        pool2=L.Pooling(relu2, pool=P.Pooling.MAX, kernel_size=3,   stride=2)
        #创建一个全连接层
        fc3=L.InnerProduct(pool2, num_output=1024,weight_filler=dict    (type='xavier'))
        relu3=L.ReLU(fc3, in_place=True)
        #创建一个dropout层
        drop3 = L.Dropout(relu3, in_place=True)
        fc4 = L.InnerProduct(drop3, num_output=10,weight_filler=dict    (type='xavier'))    #创建一个softmax层
        loss = L.SoftmaxWithLoss(fc4, label)

        if include_acc: #在训练阶段，不需要accuracy层，但是在验证阶段，是需 要的
            acc = L.Accuracy(fc4, label)
            return to_proto(loss, acc)
        else:
            return to_proto(loss)

    def write_net():
        #将以上的设置写入到prototxt文件
        # 训练的网络文件
        with open(train_proto, 'w') as f:
            f.write(str(create_net(train_lmdb,batch_size=64)))

        # 验证的网络文件
        with open(val_proto, 'w') as f:
            f.write(str(create_net(val_lmdb,batch_size=32,  include_acc=True)))

    if __name__ == '__main__':
        write_net()
    ```

2. 数据是图片格式

    ```python
    from caffe import layers as L, params as P, proto, to_proto
    import caffe

    path = '/home/xxx/data/'                #  项目路径
    train_list = path + 'train.txt'         # （读）训练集列表
    val_list = path + 'val.txt'             # （读）测试集列表
    mean_file = path + 'mean.binaryproto'   # （读）均值文件的位置
    train_proto = path + 'train.prototxt'   # （写）生成的训练配置文件保存的位置
    val_proto = path + 'val.prototxt'       # （写）生成的验证配置文件保存的位置

    def Lenet(image_list, batch_size, include_acc=False):
        data, label = L.ImageData(name="mnist", source=image_list,
                                  batch_size=batch_size, ntop=2,    root_folder=root,
                                  transform_param=dict(scale=0. 00390625))
        conv1 = L.Convolution(data, kernel_size=5, stride=1,    num_output=20,
                              pad=0, bias_filler=dict(type="constant")  ,
                              weight_filler=dict(type="xavier"))
        pool1 = L.Pooling(conv1, kernel_size=2, stride=2, pool=P.   Pooling.MAX)

        conv2 = L.Convolution(pool1, kernel_size=5, stride=1,
                              num_output=50, weight_filler=dict (type="xavier"))
        pool2 = L.Pooling(conv2, kernel_size=2, stride=2, pool=P.   Pooling.MAX)

        ip1 = L.InnerProduct(pool2, num_output=500,
                             weight_filler=dict(type="xavier"))
        relu1 = L.ReLU(ip1, in_place=True)

        ip2 = L.InnerProduct(relu1, num_output=3,
                             weight_filler=dict(type="xavier"))
        loss = L.SoftmaxWithLoss(ip2, label)

        if include_acc:
            acc = L.Accuracy(ip2, label)
            return to_proto(loss, acc)
        else:
            return to_proto(loss)

    def writeNet():
        with open(train_proto, "w") as f:
            f.write(str(Lenet(train_list, batch_size=64)))
        with open(val_proto, "w") as f:
            f.write(str(Lenet(test_list, batch_size=64, include_acc=True)))

    if __name__ == '__main__':
        writeNet()
    ```

**小结：**

1. 两种格式的区别是第一步读入数据的 api 不一样而已。
2. 用 python 编写的网络配置文件把训练网络和测试网络分开了两个文件。如果是普通的 `train_val.prototxt` 它们是写在同一个文件的，并且用 `include{
phase: TRAIN}` 参数来区分这个数据是在什么时候用。同理训练网络不需要 `acc`，在 `acc` 层也加一个 `include{phase: TEST}` 就可以区分数据在哪个阶段使用了。

## 二、生成 solver 文件

* 迭代多少代和迭代多少次的区别
  想要弄懂这个问题必须明确以下概念：

  * 训练网络的 `batch_size: 64`：代表 每批次训练的样本数量。
  * solver文件的 `test_interval`：代表 迭代多少次后开始测试。
  
  假设现在有 10000 个训练样本，`batch_size: 64`，开始训练
  每训练一次，`test_interval` 就会加一。**这叫迭代多少次。**
  训练到 $ \frac{10000}{64} = 156.25 \approx 156 次 $ 后，此时已经把10000 个训练样本都训练过了。**称之为迭代了 1 代**，即 epoch。

* 如何设置值
  首先，网络配置文件的训练和测试的 `batch_size` 一般来说是一样的。
  * `test_interval`：$ \frac{训练样本数量}{batch\_size}$ 这样把训练样本全部处理完才测试
  * `max_iter`: $ test\_interval * 代数 $ 你想要几代就训练几代
  * `test_iter`: $ \frac{测试样本数量}{batch\_size} $ 这样测试样本全部处理完才继续下一代的训练。
  * `display`: 同 `test_interval`。即训练完一代才显示 train_net的 `loss`，test_net 的 `acc` 和 `loss` 则是每 epoch 就显示一次。
  * `snapshot`: 同 `test_interval`。即训练完一代才保存。
  * `snapshot_prefix`: "backup/lenet"。文件会保存在当前文件夹下的`backup`文件夹，并且前缀是 `lenet`。
  * `solver_mode`: `caffe_pb2.SolverParameter.CPU`。根据实际修改 `GPU/CPU`
  * `stepsize`: 迭代多少次改变学习率。可以根据 $\frac{max\_iter}{你想改变的次数}$ 来设置。就是迭代100代，我想30代改变一次，就代入数据算出迭代多少次改变的值。

```python
# -*- coding: utf-8 -*-
import caffe
from caffe.proto import caffe_pb2


path = '/home/cooneo/tmp/handClassify/'  # 项目路径
train_net = path + 'train.prototxt'      # (读) 训练网络的文件
test_net = path + 'val.prototxt'         # (读) 测试网络的文件
solver_file = path+'solver.prototxt'     # (写) 保存路径+名字
train_photos_num = 1602  # 训练样本的数量 --- 需更改
val_photos_num = 400     # 测试样本的数量 --- 需更改
epoch_num = 100          # 迭代多少代     --- 需更改
num_to_change_lr = 10    # 要改变多少次学习率 --- 需更改
batch_size = 32          # 网络文件的 batch_size  --- 可能需更改
test_interval = 1+int(train_photos_num/batch_size)  # 测试间隔
test_iter = 1+int(val_photos_num/batch_size)  # 测试迭代的次数


def gen_solver(solver_file,train_net,test_net):
    s = caffe.proto.caffe_pb2.SolverParameter()
    s.train_net = train_net # 训练网络文件
    s.test_net.append(test_net) # 测试网络文件

    s.test_interval = test_interval  # 训练迭代n次后开始测试，根据迭代完所有的训练样本设置。
    s.test_iter.append(test_iter) # 测试样本迭代n次。
    s.max_iter = test_interval*epoch_num # 训练迭代多少次。根据你想要迭代多少代，即epoch去设置
    s.display = test_interval*10 # 显示间隔
    s.snapshot = int(test_interval*epoch_num/5) # 保存间隔
    s.snapshot_prefix = 'bkp/shapshot' # 保存文件的路径+前缀
    s.solver_mode = caffe_pb2.SolverParameter.CPU

    s.base_lr = 0.001
    s.momentum = 0.9
    s.weight_decay = 5e-4
    s.lr_policy = 'step'
    s.stepsize = int(test_interval*epoch_num/num_to_change_lr)
    s.gamma = 0.1
    s.type = "SGD"

    with open(solver_file, 'w') as f:
        f.write(str(s))

if __name__ == '__main__':
    gen_solver(solver_file, train_net, test_net)
```

## 三、生成 deploy 文件

### 法一(推荐)：直接用 test.prototxt 文件修改

```prototxt
// 首先把 test 网络的输入层删掉，添加以下层，注意以下层的输出是 "data"
layer {
  name: "data"
  type: "Input"
  top: "data" // 可能需要改这里
  input_param { shape: { dim: 64 dim: 1 dim: 28 dim: 28 } }
}
// 如果卷积层的输入不是 "data"，修改一下
// ... ...
// 到最后，把 acc 和 loss 层都删掉，添加以下的 "Softmax" 层
layer {
  name: "prob"
  type: "Softmax"
  bottom: "ip2" // 注意全连接层的输出层的名字，可能需要改这里
  top: "prob"
}
```

### 法二：用 python 生成

```python
# -*- coding: utf-8 -*-
# 应根据实际修改层的配置
from caffe import layers as L,params as P,to_proto
root='/home/xxx/'
deploy=root+'mnist/deploy.prototxt'    #文件保存路径

def create_deploy():
    # 少了第一层，data层
    conv1=L.Convolution(bottom='data', kernel_size=5, stride=1,num_output=20, pad=0,weight_filler=dict(type='xavier'))
    pool1=L.Pooling(conv1, pool=P.Pooling.MAX, kernel_size=2, stride=2)
    conv2=L.Convolution(pool1, kernel_size=5, stride=1,num_output=50, pad=0,weight_filler=dict(type='xavier'))
    pool2=L.Pooling(conv2, pool=P.Pooling.MAX, kernel_size=2, stride=2)
    fc3=L.InnerProduct(pool2, num_output=500,weight_filler=dict(type='xavier'))
    relu3=L.ReLU(fc3, in_place=True)
    fc4 = L.InnerProduct(relu3, num_output=10,weight_filler=dict(type='xavier'))
    # 最后没有 acc 和 loss 层，但有一个Softmax层
    prob=L.Softmax(fc4)
    return to_proto(prob)

def write_deploy():
    with open(deploy, 'w') as f:
        f.write('name:"Lenet"\n')
        f.write('input:"data"\n')
        f.write('input_dim:1\n')
        f.write('input_dim:3\n')
        f.write('input_dim:28\n')
        f.write('input_dim:28\n')
        f.write(str(create_deploy()))
if __name__ == '__main__':
    write_deploy()
```

## 四、训练

```python
solver_file = "solver.prototxt"
def training(solver_file):
    caffe.set_mode_cpu()
    # 如果是 gpu，用以下两条
    # caffe.set_device(0)  # 一般都是 gpu0
    # caffe.set_mode_gpu()
    solver = caffe.SGDSolver(solver_file)
    solver.solve()

if __name__ == '__main__':
    training(solver_file)
```

## 五、用训练好的模型进行分类

### 5.1 python 版

```python
import caffe
import numpy as np
import time

# ---------------------- 需要修改的变量 ----------------------
root = "./" # 项目路径
deploy = root + "deploy/deploy.prototxt" # deploy 文件
caffemodel = root + "deploy/lenet_iter_7315.caffemodel" # 训练好的 caffemodel
labelsFile = root + "deploy/labels.txt" # 类别名称文件
imgPath = "data/test/scissor/1763.jpg"  # 待分类的图片路径
# ----------------------------------------------------------  

# 加载网络
net = caffe.Net(deploy, caffemodel, caffe.TEST)

# 开始计时(计算图片分类所需时间)
start = time.clock()

# 图片预处理
transformer = caffe.io.Transformer({"data": net.blobs["data"].data.shape}) # 设定图片的 shape 格式（从加载的deploy文件读取 shape 值，假设为 1，3，28，28）
transformer.set_transpose("data", (2, 0, 1)) # 改变维度顺序，由原始图片（28，28，3）变为（3，28，28）
# transformer.set_mean('data', np.load(mean_file).mean(1).mean(1)) #减去均值，前面训练模型时没有减均值，这儿就不用
transformer.set_raw_scale("data", 255) # 缩放到[0,255]之间
transformer.set_channel_swap("data", (2, 1, 0)) # 交换通道，RGB 变为 BGR

img = caffe.io.load_image(imgPath) # 加载图片
net.blobs["data"].data[...] = transformer.preprocess("data", img) # 执行上面设置的图片预处理操作，并将图片载入到 blob 中

out = net.forward() # 前向传播

labels = np.loadtxt(labelsFile, str, delimiter='\t') # 加载类别名称文件按
prob = net.blobs["Softmax1"].data[0].flatten() # 取出最后一层"Softmax1"属于某个类别的概率值。注意这个是根据 deploy 文件的最后一层的名称填写。
order = prob.argsort()[-1] # 将概率值排序，并取出最大值所在的序号

# 结束计时
end = time.clock()
print("Runtime: %d ms" % ((end-start)*1000))
print(prob) # 输出概率
print("the calss is : ", labels[order])
```

### 5.2 c++ 版

* 该程序结合 OpenCV 4.3.0 和 3.4.0 的官方例程修改的，主要是去除了解析命令行的相关代码

```c++
#include <fstream>
#include <sstream>
#include <opencv2/dnn.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>

using namespace cv;
using namespace dnn;

// ----------------- 需要修改的变量 ----------------
String model = "deploy/lenet_iter_7315.caffemodel";
String config = "deploy/deploy.prototxt";
String labelFile = "./deploy/labels.txt";
String imgPath = "./data/1642.jpg";
int inpWidth = 120;  // the input image's width
int inpHeight = 120; //the input image's height
// -----------------------------------------------

std::vector<std::string> classes;

int main(int argc, char **argv)
{
    // 读取类别名称文件
    std::ifstream ifs(labelFile.c_str());
    if (!ifs.is_open())
        CV_Error(Error::StsError, "File " + labelFile + " not found");
    std::string line;
    while (std::getline(ifs, line))
    {
        classes.push_back(line);
    }

    CV_Assert(!model.empty());

    //! [Read and initialize network]
    Net net = readNet(model, config);
    //! [Read and initialize network]

    // Create a window
    static const std::string kWinName = "Deep learning image classification in OpenCV";
    namedWindow(kWinName, WINDOW_NORMAL);

    // Process frames.
    Mat img, blob;
    img = imread(imgPath);
    //! [Create a 4D blob from a frame]
    // 需要注意的是 Scalar(104, 117, 123) 为均值
    blobFromImage(img, blob, 1.0f, Size(inpWidth, inpHeight), Scalar(104, 117, 123), false);
    //! [Create a 4D blob from a frame]

    //! [Set input blob]
    net.setInput(blob);
    //! [Set input blob]

    //! [Make forward pass]
    Mat prob = net.forward();
    //! [Make forward pass]

    //! [Get a class with a highest score]
    Point classIdPoint;
    double confidence;
    minMaxLoc(prob.reshape(1, 1), 0, &confidence, 0, &classIdPoint);
    int classId = classIdPoint.x;
    //! [Get a class with a highest score]

    // Put efficiency information.
    std::vector<double> layersTimes;
    double freq = getTickFrequency() / 1000;
    double t = net.getPerfProfile(layersTimes) / freq;
    std::string label = format("Inference time: %.2f ms", t);
    putText(img, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.3, Scalar(0, 255, 0));

    // Print predicted class.
    label = format("%s: %.4f", (classes.empty() ? format("Class #%d", classId).c_str() : classes[classId].c_str()),
                   confidence);
    putText(img, label, Point(0, 40), FONT_HERSHEY_SIMPLEX, 0.3, Scalar(0, 255, 0));

    imshow(kWinName, img);
    waitKey(0);
    return 0;
}
```

## 参考

1. [caffe的python接口学习（1）：生成配置文件](https://www.cnblogs.com/denny402/p/5679037.html)
2. [caffe的python接口学习（2）：生成solver文件](https://www.cnblogs.com/denny402/p/5679154.html)
3. [caffe的python接口学习（5）：生成deploy文件](https://www.cnblogs.com/denny402/p/5685818.html)
4. [caffe的python接口学习（6）：用训练好的模型（caffemodel）来分类新的图片](https://www.cnblogs.com/denny402/p/5685909.html)
5. [OpenCV4.3.0 关于读取 caffemodel 的例程](https://docs.opencv.org/4.3.0/d5/de7/tutorial_dnn_googlenet.html)
6. [OpenCV3.4.0 关于读取 caffemodel 的例程](https://docs.opencv.org/3.4.0/d5/de7/tutorial_dnn_googlenet.html)
